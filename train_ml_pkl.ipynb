{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd5848fd-3a9e-40f3-b40c-4a66b96ff2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retriving the data from mysql server----->creating ml model and save it to pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c95bc5-2c39-4aef-9adb-15b240516f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š GradientBoosting Results:\n",
      "RÂ² Score: 0.5932\n",
      "RMSE: 1105539.12\n",
      "\n",
      "ðŸ“Š RandomForest Results:\n",
      "RÂ² Score: 0.5634\n",
      "RMSE: 1186785.85\n",
      "\n",
      "ðŸ“Š LinearRegression Results:\n",
      "RÂ² Score: 0.4077\n",
      "RMSE: 1609954.19\n",
      "\n",
      "âœ… Best Model: GradientBoosting (RÂ² = 0.5932) saved successfully as bigmart_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === 1. Connect to MySQL and Load Data ===\n",
    "connection = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='varun@07',\n",
    "    database='bigmart'\n",
    ")\n",
    "\n",
    "df_item = pd.read_sql(\"SELECT * FROM item_info\", connection)\n",
    "df_outlet = pd.read_sql(\"SELECT * FROM outlet_info\", connection)\n",
    "df_sales = pd.read_sql(\"SELECT * FROM sales_info\", connection)\n",
    "connection.close()\n",
    "\n",
    "# === 2. Merge DataFrames ===\n",
    "df = df_item.merge(df_outlet, on='ID').merge(df_sales, on='ID')\n",
    "df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# === 3. Feature Engineering ===\n",
    "df['Outlet_Age'] = 2025 - df['Outlet_Establishment_Year']\n",
    "df.drop('Outlet_Establishment_Year', axis=1, inplace=True)\n",
    "\n",
    "df['Item_Fat_Content'] = df['Item_Fat_Content'].replace({\n",
    "    'low fat': 'Low Fat',\n",
    "    'LF': 'Low Fat',\n",
    "    'reg': 'Regular'\n",
    "})\n",
    "\n",
    "df['Item_Visibility'] = np.where(df['Item_Visibility'] > 0.3, 0.3, df['Item_Visibility'])\n",
    "\n",
    "# === 4. Prepare X, y ===\n",
    "X = df.drop('Item_Outlet_Sales', axis=1)\n",
    "y = df['Item_Outlet_Sales']\n",
    "\n",
    "# === 5. Categorical Columns ===\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# === 6. Preprocessing Pipeline ===\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# === 7. Define Models to Compare ===\n",
    "models = {\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(n_estimators=200, learning_rate=0.1, random_state=42),\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=200, random_state=42),\n",
    "    \"LinearRegression\": LinearRegression()\n",
    "}\n",
    "\n",
    "# === 8. Train/Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === 9. Evaluate All Models ===\n",
    "best_model_name = None\n",
    "best_score = -np.inf\n",
    "best_pipeline = None\n",
    "\n",
    "for name, reg in models.items():\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', reg)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"\\nðŸ“Š {name} Results:\")\n",
    "    print(f\"RÂ² Score: {r2:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    if r2 > best_score:\n",
    "        best_score = r2\n",
    "        best_model_name = name\n",
    "        best_pipeline = pipeline\n",
    "\n",
    "# === 10. Save Best Model using Pickle ===\n",
    "with open(\"bigmart_best_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump((best_pipeline, sklearn.__version__), f)\n",
    "\n",
    "print(f\"\\nâœ… Best Model: {best_model_name} (RÂ² = {best_score:.4f}) saved successfully as bigmart_best_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc562ec-5187-476c-8d18-1752e4dac2d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
